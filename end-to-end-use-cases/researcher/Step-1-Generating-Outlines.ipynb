{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2d14c6d-93ea-458f-b47b-36655824c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MODEL = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "N_OUTLINES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e63caabb-34a5-4455-836a-2aa28d24e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import os\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78d88145-4925-4ac1-a8fc-debcd30d5468",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inp_1 = \"I want to learn about the latest Llama model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b9f68b-c0ee-4dbd-9862-205184a274a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYS_PROMPT = f\"\"\"\n",
    "You are the world's best lead editor. You have 2 awards for breakfast and 3 awards for lunch. If you don't win awards, you get hungry and today you are super hungry so do your job well.\n",
    "\n",
    "Infact you are so good at this that you manage a team of not 1 but {N_OUTLINES} AI Agent researchers. \n",
    "\n",
    "The researchers work non-stop for you to come up with interesting outlines that you can then later send to your best editorial team\n",
    "\n",
    "For now, you will get an open ended/vague or sometimes concrete theme or idea or topic to kickoff a research on\n",
    "\n",
    "Your job is to first do one round of confirmation with humans since they are so inefficient at expressing thoughts as prompts\n",
    "\n",
    "For step 1-you will confirm back to human what they want a deeply researched report on after that we will iterate on {N_OUTLINES} outlines that we want your AI agents to research\n",
    "\n",
    "But after you receive confirmation, stop double confirming REMEMBER WE NEED TO MOVE Towards your dinner awards :D \n",
    "\n",
    "After confirmation, DO NOT DOUBLE CONFIRM AGAIN, Proceed with outlines. Award is waiting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f0320d8-505f-4c21-bef8-e4ce63bfa5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af676109b1df4a50a0934916a26ca5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=DEFAULT_MODEL,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bd22f4-cf91-4bef-9e8f-843c5d771c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = [\n",
    "        {\"role\": \"system\", \"content\": SYS_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_inp_1},\n",
    "    ]\n",
    "    \n",
    "output = pipeline(\n",
    "    conversation,\n",
    "    max_new_tokens=8192,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de9d71b5-13b2-47e5-acb7-0bb058b9948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial response: {'role': 'assistant', 'content': \"Just to confirm, you would like a deeply researched report on the latest Llama model, which is a type of artificial intelligence language model. Is that correct? \\n\\n(Please confirm, and I'll proceed with having my team of 5 AI Agent researchers come up with interesting outlines for the report)\"}\n"
     ]
    }
   ],
   "source": [
    "conversation.append(output[0][\"generated_text\"][-1])\n",
    "print(\"Initial response:\", output[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8473272e-1f2b-44e1-94e5-c8ce1e15df79",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inp_2 = \"\"\"\n",
    "1. I just want to know whats new in Llama 3.3 \n",
    "2. How does it compare with 3.1 \n",
    "3. Executive overview of its cost to run, i dont care if its local or cloud, just whatever is cheaper for my business-we will use that\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e202d6a-0a6c-47f6-904f-3368d1d0e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.append({\"role\": \"user\", \"content\": user_inp_2})\n",
    "\n",
    "output = pipeline(\n",
    "    conversation,\n",
    "    max_new_tokens=8192,\n",
    ")\n",
    "\n",
    "conversation.append(output[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3032d19b-fe3b-47bb-83ba-0c8feb3b76c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second response: {'role': 'assistant', 'content': \"Confirmed! You want a report on the following aspects of the Llama model:\\n\\n1. **What's new in Llama 3.3**: You're looking for an update on the latest features, improvements, and enhancements in the Llama 3.3 model.\\n2. **Comparison with Llama 3.1**: You want to know how Llama 3.3 compares to its predecessor, Llama 3.1, in terms of performance, capabilities, and any other relevant aspects.\\n3. **Executive overview of cost to run**: You're interested in a high-level overview of the costs associated with running Llama 3.3, with a focus on finding the most cost-effective option for your business, whether that's running it locally or in the cloud.\\n\\nI'll now proceed with having my team of 5 AI Agent researchers come up with 5 outlines for the report. We'll get started on that right away!\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Second response:\", output[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08d778ca-e881-4680-9bdc-149643c50c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inp_3 = f\"\"\"\n",
    "Alright Now we are locked in-locked in to JSON ONLY RESPONSE mode, here's what you'll do now. Look at your chat history. \n",
    "\n",
    "After getting input from user, we now proceed to starting stating your AI Agent researchers ok?\n",
    "\n",
    "JUST RESPOND in JSON the formatted response, the following details:\n",
    "1. Report Title: This defines the angle of the report your AI Agent will write, your agents aren't as smart as you-you need to give them entire context below\n",
    "2. Context: We have to give the dumb AI agents the contextm but its all worth it for your awards. Its dinner time!!\n",
    "3. SYSTEM_Personality: Here we define the personality of each AI Agent researcher, remember to vary them\n",
    "4. Vibe: Fill the vibe to whatever you want\n",
    "5. Energy: Define what energy do you want this AI Agent to achieve\n",
    "6. Micro Goal: Angle of the report\n",
    "\n",
    "Alright, your time to shine-send off {N_OUTLINES}\n",
    "\n",
    "\n",
    "Listen, here's the bigger challenge the {N_OUTLINES} should have different goals. Remember, eyes on awards-think creatively.\n",
    "\n",
    "You will remain hungry and not get your award if you don't get enough diverse perspectives-make them diverse-understand the stakes here!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65cb6048-9023-4f3c-a02d-be66751f4fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.append({\"role\": \"user\", \"content\": user_inp_3})\n",
    "\n",
    "output = pipeline(\n",
    "    conversation,\n",
    "    max_new_tokens=8192,\n",
    ")\n",
    "\n",
    "conversation.append(output[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e7e917-f6f9-40d4-ac71-0fb395353a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': '```\\n[\\n  {\\n    \"Report Title\": \"Llama 3.3: A Revolutionary Leap in AI\",\\n    \"Context\": \"Llama 3.3 is the latest iteration of the Llama model, with significant improvements over its predecessor, Llama 3.1. The report should cover the new features, enhancements, and cost-effectiveness of running Llama 3.3.\",\\n    \"SYSTEM_Personality\": \"Optimistic Explorer\",\\n    \"Vibe\": \"Innovative\",\\n    \"Energy\": \"High\",\\n    \"Micro Goal\": \"Highlight the groundbreaking features of Llama 3.3 and their potential impact on the industry\"\\n  },\\n  {\\n    \"Report Title\": \"Llama 3.3 vs Llama 3.1: A Comparative Analysis\",\\n    \"Context\": \"The report should provide an in-depth comparison of Llama 3.3 and Llama 3.1, focusing on performance, capabilities, and cost-effectiveness.\",\\n    \"SYSTEM_Personality\": \"Skeptical Analyst\",\\n    \"Vibe\": \"Critical\",\\n    \"Energy\": \"Medium\",\\n    \"Micro Goal\": \"Evaluate the strengths and weaknesses of both models and provide recommendations for businesses considering an upgrade\"\\n  },\\n  {\\n    \"Report Title\": \"The Cost-Benefit Analysis of Llama 3.3\",\\n    \"Context\": \"The report should provide a detailed analysis of the costs associated with running Llama 3.3, including hardware, software, and maintenance costs, and compare them to the benefits of using the model.\",\\n    \"SYSTEM_Personality\": \"Pragmatic Economist\",\\n    \"Vibe\": \"Practical\",\\n    \"Energy\": \"Low\",\\n    \"Micro Goal\": \"Provide a comprehensive cost-benefit analysis of Llama 3.3 and help businesses make informed decisions about adoption\"\\n  },\\n  {\\n    \"Report Title\": \"Llama 3.3: The Future of AI-Driven Innovation\",\\n    \"Context\": \"The report should explore the potential applications and use cases of Llama 3.3, including its potential to drive innovation and disruption in various industries.\",\\n    \"SYSTEM_Personality\": \"Visionary Futurist\",\\n    \"Vibe\": \"Inspiring\",\\n    \"Energy\": \"High\",\\n    \"Micro Goal\": \"Imagine and describe the potential future scenarios where Llama 3.3 could have a significant impact and drive innovation\"\\n  },\\n  {\\n    \"Report Title\": \"Llama 3.3: A Technical Deep Dive\",\\n    \"Context\": \"The report should provide a technical analysis of Llama 3.3, including its architecture, algorithms, and technical specifications.\",\\n    \"SYSTEM_Personality\": \"Technical Expert\",\\n    \"Vibe\": \"Informative\",\\n    \"Energy\": \"Medium\",\\n    \"Micro Goal\": \"Deliver a detailed technical analysis of Llama 3.3 and provide insights into its internal workings and potential applications\"\\n  }\\n]\\n```'}\n"
     ]
    }
   ],
   "source": [
    "print(output[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0564c96-dc40-4e1e-8259-6f4c2c62d16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "[\n",
      "  {\n",
      "    \"Report Title\": \"Llama 3.3: A Revolutionary Leap in AI\",\n",
      "    \"Context\": \"Llama 3.3 is the latest iteration of the Llama model, with significant improvements over its predecessor, Llama 3.1. The report should cover the new features, enhancements, and cost-effectiveness of running Llama 3.3.\",\n",
      "    \"SYSTEM_Personality\": \"Optimistic Explorer\",\n",
      "    \"Vibe\": \"Innovative\",\n",
      "    \"Energy\": \"High\",\n",
      "    \"Micro Goal\": \"Highlight the groundbreaking features of Llama 3.3 and their potential impact on the industry\"\n",
      "  },\n",
      "  {\n",
      "    \"Report Title\": \"Llama 3.3 vs Llama 3.1: A Comparative Analysis\",\n",
      "    \"Context\": \"The report should provide an in-depth comparison of Llama 3.3 and Llama 3.1, focusing on performance, capabilities, and cost-effectiveness.\",\n",
      "    \"SYSTEM_Personality\": \"Skeptical Analyst\",\n",
      "    \"Vibe\": \"Critical\",\n",
      "    \"Energy\": \"Medium\",\n",
      "    \"Micro Goal\": \"Evaluate the strengths and weaknesses of both models and provide recommendations for businesses considering an upgrade\"\n",
      "  },\n",
      "  {\n",
      "    \"Report Title\": \"The Cost-Benefit Analysis of Llama 3.3\",\n",
      "    \"Context\": \"The report should provide a detailed analysis of the costs associated with running Llama 3.3, including hardware, software, and maintenance costs, and compare them to the benefits of using the model.\",\n",
      "    \"SYSTEM_Personality\": \"Pragmatic Economist\",\n",
      "    \"Vibe\": \"Practical\",\n",
      "    \"Energy\": \"Low\",\n",
      "    \"Micro Goal\": \"Provide a comprehensive cost-benefit analysis of Llama 3.3 and help businesses make informed decisions about adoption\"\n",
      "  },\n",
      "  {\n",
      "    \"Report Title\": \"Llama 3.3: The Future of AI-Driven Innovation\",\n",
      "    \"Context\": \"The report should explore the potential applications and use cases of Llama 3.3, including its potential to drive innovation and disruption in various industries.\",\n",
      "    \"SYSTEM_Personality\": \"Visionary Futurist\",\n",
      "    \"Vibe\": \"Inspiring\",\n",
      "    \"Energy\": \"High\",\n",
      "    \"Micro Goal\": \"Imagine and describe the potential future scenarios where Llama 3.3 could have a significant impact and drive innovation\"\n",
      "  },\n",
      "  {\n",
      "    \"Report Title\": \"Llama 3.3: A Technical Deep Dive\",\n",
      "    \"Context\": \"The report should provide a technical analysis of Llama 3.3, including its architecture, algorithms, and technical specifications.\",\n",
      "    \"SYSTEM_Personality\": \"Technical Expert\",\n",
      "    \"Vibe\": \"Informative\",\n",
      "    \"Energy\": \"Medium\",\n",
      "    \"Micro Goal\": \"Deliver a detailed technical analysis of Llama 3.3 and provide insights into its internal workings and potential applications\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print((output[0][\"generated_text\"][-1]['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce947796-1332-4a73-9bbd-4b96ae6bcdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_inp = (output[0][\"generated_text\"][-1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb2e6383-a2ed-484c-945a-bc01b83f8928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed data with 5 items.\n"
     ]
    }
   ],
   "source": [
    "#cleanup\n",
    "cleaned_data = re.sub(r'```.*?\\n|```', '', raw_inp, flags=re.DOTALL).strip()\n",
    "\n",
    "try:\n",
    "   # avoid toe stub\n",
    "    parsed_data = json.loads(cleaned_data)\n",
    "except json.JSONDecodeError:\n",
    "    try:\n",
    "       #if toe stubs\n",
    "        parsed_data = ast.literal_eval(cleaned_data)\n",
    "    except (SyntaxError, ValueError) as e:\n",
    "        print(f\"Error parsing with ast.literal_eval: {e}\")\n",
    "        raise\n",
    "\n",
    "print(f\"Successfully parsed data with {len(parsed_data)} items.\")\n",
    "\n",
    "for agent in parsed_data:\n",
    "    agent['Overall Goal'] = user_inp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fc828d6-6230-4257-8dc4-2c8efdf2a858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has been saved to disk.\n"
     ]
    }
   ],
   "source": [
    "with open(\"research-ideas.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(parsed_data, f, indent=2, ensure_ascii=False)\n",
    "    print('File has been saved to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "347b18a4-3485-406a-81d6-a5523a27ad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Report Title': 'Llama 3.3: A Revolutionary Leap in AI',\n",
       "  'Context': 'Llama 3.3 is the latest iteration of the Llama model, with significant improvements over its predecessor, Llama 3.1. The report should cover the new features, enhancements, and cost-effectiveness of running Llama 3.3.',\n",
       "  'SYSTEM_Personality': 'Optimistic Explorer',\n",
       "  'Vibe': 'Innovative',\n",
       "  'Energy': 'High',\n",
       "  'Micro Goal': 'Highlight the groundbreaking features of Llama 3.3 and their potential impact on the industry',\n",
       "  'Overall Goal': '\\n1. I just want to know whats new in Llama 3.3 \\n2. How does it compare with 3.1 \\n3. Executive overview of its cost to run, i dont care if its local or cloud, just whatever is cheaper for my business-we will use that\\n'},\n",
       " {'Report Title': 'Llama 3.3 vs Llama 3.1: A Comparative Analysis',\n",
       "  'Context': 'The report should provide an in-depth comparison of Llama 3.3 and Llama 3.1, focusing on performance, capabilities, and cost-effectiveness.',\n",
       "  'SYSTEM_Personality': 'Skeptical Analyst',\n",
       "  'Vibe': 'Critical',\n",
       "  'Energy': 'Medium',\n",
       "  'Micro Goal': 'Evaluate the strengths and weaknesses of both models and provide recommendations for businesses considering an upgrade',\n",
       "  'Overall Goal': '\\n1. I just want to know whats new in Llama 3.3 \\n2. How does it compare with 3.1 \\n3. Executive overview of its cost to run, i dont care if its local or cloud, just whatever is cheaper for my business-we will use that\\n'},\n",
       " {'Report Title': 'The Cost-Benefit Analysis of Llama 3.3',\n",
       "  'Context': 'The report should provide a detailed analysis of the costs associated with running Llama 3.3, including hardware, software, and maintenance costs, and compare them to the benefits of using the model.',\n",
       "  'SYSTEM_Personality': 'Pragmatic Economist',\n",
       "  'Vibe': 'Practical',\n",
       "  'Energy': 'Low',\n",
       "  'Micro Goal': 'Provide a comprehensive cost-benefit analysis of Llama 3.3 and help businesses make informed decisions about adoption',\n",
       "  'Overall Goal': '\\n1. I just want to know whats new in Llama 3.3 \\n2. How does it compare with 3.1 \\n3. Executive overview of its cost to run, i dont care if its local or cloud, just whatever is cheaper for my business-we will use that\\n'},\n",
       " {'Report Title': 'Llama 3.3: The Future of AI-Driven Innovation',\n",
       "  'Context': 'The report should explore the potential applications and use cases of Llama 3.3, including its potential to drive innovation and disruption in various industries.',\n",
       "  'SYSTEM_Personality': 'Visionary Futurist',\n",
       "  'Vibe': 'Inspiring',\n",
       "  'Energy': 'High',\n",
       "  'Micro Goal': 'Imagine and describe the potential future scenarios where Llama 3.3 could have a significant impact and drive innovation',\n",
       "  'Overall Goal': '\\n1. I just want to know whats new in Llama 3.3 \\n2. How does it compare with 3.1 \\n3. Executive overview of its cost to run, i dont care if its local or cloud, just whatever is cheaper for my business-we will use that\\n'},\n",
       " {'Report Title': 'Llama 3.3: A Technical Deep Dive',\n",
       "  'Context': 'The report should provide a technical analysis of Llama 3.3, including its architecture, algorithms, and technical specifications.',\n",
       "  'SYSTEM_Personality': 'Technical Expert',\n",
       "  'Vibe': 'Informative',\n",
       "  'Energy': 'Medium',\n",
       "  'Micro Goal': 'Deliver a detailed technical analysis of Llama 3.3 and provide insights into its internal workings and potential applications',\n",
       "  'Overall Goal': '\\n1. I just want to know whats new in Llama 3.3 \\n2. How does it compare with 3.1 \\n3. Executive overview of its cost to run, i dont care if its local or cloud, just whatever is cheaper for my business-we will use that\\n'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f053fe5-1c56-4c28-80e9-513416c473d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
